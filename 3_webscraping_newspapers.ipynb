{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the Newspaper module\n",
    "\n",
    "This module makes it much easier to scrape newspapers. Rather than investigating the structure of the webpage, the Newspaper module is capable of understanding the structure of many news sites and doing the hard work for you.\n",
    "\n",
    "Sites I have tested this with:\n",
    "- https://cnn.com/\n",
    "- https://bbc.co.uk/\n",
    "- https://www.telegraph.co.uk/\n",
    "- https://www.theguardian.com/\n",
    "\n",
    "**IMPORTANT** Before you begin you need to install the Newspaper module by running the followin code block. You only need to do this once for every Noteable session\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install newspaper3k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping the news site\n",
    "Now we have installed the Newspapers module we can use it to scrape the site.\n",
    "\n",
    "The following code block by default will search the guardian site and write results to 'guardian.csv'\n",
    "\n",
    "To change this, enter a different URL in the 'news_source' variable and enter a different filename in the 'csv_file' variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import newspaper\n",
    "import csv\n",
    "import os\n",
    "from datetime import date\n",
    "\n",
    "today = date.today()\n",
    "\n",
    "# Declare news source\n",
    "news_source = 'https://www.theguardian.com/'\n",
    "# news_source = 'https://bbc.co.uk/'\n",
    "# news_source = 'https://www.telegraph.co.uk/'\n",
    "# news_source = 'https://cnn.com/'\n",
    "\n",
    "# declare export file name - news articles are written to this csv file\n",
    "csv_file = 'guardian.csv'\n",
    "\n",
    "paper = newspaper.build(news_source,  memoize_articles=False)\n",
    "\n",
    "# create empty list for existing news article links\n",
    "links = []\n",
    "\n",
    "# Check if csv already exists and if so store the news article links in a list\n",
    "if os.path.exists(csv_file):\n",
    "    with open(csv_file, 'r') as f:\n",
    "        csvreader = csv.reader(f, delimiter=\",\")\n",
    "        for row in csvreader:\n",
    "            links.append(row[2])\n",
    "            print(row[2]) # show existing links\n",
    "\n",
    "\n",
    "# Open the file ready for writing\n",
    "file = open(csv_file, \"a\")\n",
    "writer = csv.writer(file, quoting=csv.QUOTE_ALL)\n",
    "\n",
    "cnt = 0 # Set a counter\n",
    "\n",
    "\n",
    "for article in paper.articles:\n",
    "    if article.url not in links:\n",
    "        # Retrieving the page\n",
    "        article.download()\n",
    "        article.parse()\n",
    "\n",
    "        # Getting the article link\n",
    "        link = article.url\n",
    "\n",
    "        # Getting the title\n",
    "        title = article.title\n",
    "\n",
    "        # Getting the authors\n",
    "        authors = article.authors\n",
    "        authors = ', '.join(authors) # convert authors to a comma separated list\n",
    "\n",
    "        # Get  all of the page content\n",
    "        txt = article.text\n",
    "\n",
    "        # Removing line-breaks\n",
    "        txt = txt.replace('\\n', ' ').replace('\\r', '')\n",
    "\n",
    "        # Get publication date\n",
    "        pubdate = article.publish_date\n",
    "\n",
    "        # Perform Natural Language Processing on text to extract keywords\n",
    "        article.nlp()\n",
    "        keywords = ', '.join(article.keywords) # convert keywords to a comma separated list\n",
    "\n",
    "        if txt != None:  # Check there is an article on the page\n",
    "\n",
    "            # Check if article exists already\n",
    "           # if link not in links:\n",
    "            print('Retrieving article -- ' + title)\n",
    "            cnt += 1\n",
    "            writer.writerow([pubdate, title, link, authors, txt, keywords])\n",
    "\n",
    "print('Added ' + str(cnt) + ' news articles to ' + csv_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
